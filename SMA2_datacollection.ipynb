{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba2f3ba-cfad-49ba-9dcd-243a09c77482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\user\\anaconda3\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (3.7.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: textblob in c:\\users\\user\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\user\\anaconda3\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: gensim in c:\\users\\user\\anaconda3\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.9.3)\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.44.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (75.6.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.53.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
      "Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/124.9 MB 6.7 MB/s eta 0:00:19\n",
      "    --------------------------------------- 2.9/124.9 MB 7.0 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 3.9/124.9 MB 6.5 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 5.2/124.9 MB 6.5 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.6/124.9 MB 6.5 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 7.9/124.9 MB 6.2 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 9.2/124.9 MB 6.3 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 10.2/124.9 MB 6.2 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 11.3/124.9 MB 6.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 12.6/124.9 MB 6.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 13.9/124.9 MB 6.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 14.7/124.9 MB 5.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 15.7/124.9 MB 5.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 16.8/124.9 MB 5.7 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 17.8/124.9 MB 5.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 18.6/124.9 MB 5.6 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 19.9/124.9 MB 5.6 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 21.0/124.9 MB 5.6 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 22.0/124.9 MB 5.6 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 23.3/124.9 MB 5.6 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 24.1/124.9 MB 5.5 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 24.9/124.9 MB 5.5 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 26.0/124.9 MB 5.4 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 26.7/124.9 MB 5.3 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 27.8/124.9 MB 5.3 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 28.6/124.9 MB 5.3 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 29.6/124.9 MB 5.3 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 30.7/124.9 MB 5.3 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 31.5/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 32.5/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 33.6/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 34.6/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 5.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 4.2 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 4.2 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 4.2 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 3.9 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 3.9 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 3.9 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 3.9 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 3.9 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 3.9 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 3.9 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 3.9 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 35.9/124.9 MB 3.9 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 36.2/124.9 MB 3.3 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 36.2/124.9 MB 3.3 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 36.2/124.9 MB 3.3 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 36.2/124.9 MB 3.3 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 36.2/124.9 MB 3.3 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 36.2/124.9 MB 3.3 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 36.4/124.9 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 36.4/124.9 MB 3.0 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 36.7/124.9 MB 2.9 MB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 37.2/124.9 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 37.5/124.9 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 37.7/124.9 MB 2.8 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 38.0/124.9 MB 2.8 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 38.3/124.9 MB 2.7 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 38.8/124.9 MB 2.7 MB/s eta 0:00:32\n",
      "   ------------ --------------------------- 39.6/124.9 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------ --------------------------- 40.4/124.9 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------- -------------------------- 41.2/124.9 MB 2.8 MB/s eta 0:00:31\n",
      "   ------------- -------------------------- 42.2/124.9 MB 2.8 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 43.0/124.9 MB 2.8 MB/s eta 0:00:30\n",
      "   -------------- ------------------------- 43.8/124.9 MB 2.8 MB/s eta 0:00:29\n",
      "   -------------- ------------------------- 44.8/124.9 MB 2.9 MB/s eta 0:00:29\n",
      "   -------------- ------------------------- 45.6/124.9 MB 2.9 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 46.7/124.9 MB 2.9 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 47.7/124.9 MB 2.9 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 48.2/124.9 MB 2.9 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 48.8/124.9 MB 2.9 MB/s eta 0:00:27\n",
      "   --------------- ------------------------ 49.5/124.9 MB 2.9 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 50.3/124.9 MB 2.9 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 51.1/124.9 MB 2.9 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 51.9/124.9 MB 3.0 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 52.7/124.9 MB 3.0 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 53.7/124.9 MB 3.0 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 54.8/124.9 MB 3.0 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 55.6/124.9 MB 3.0 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 56.4/124.9 MB 3.0 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 57.1/124.9 MB 3.0 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 57.9/124.9 MB 3.0 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 58.5/124.9 MB 3.0 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 59.2/124.9 MB 3.0 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 60.0/124.9 MB 3.1 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 61.1/124.9 MB 3.1 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 62.1/124.9 MB 3.1 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 63.2/124.9 MB 3.1 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 64.2/124.9 MB 3.1 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 65.3/124.9 MB 3.1 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 66.3/124.9 MB 3.2 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 67.1/124.9 MB 3.2 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 67.9/124.9 MB 3.2 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 68.9/124.9 MB 3.2 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 69.7/124.9 MB 3.2 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 70.8/124.9 MB 3.2 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 71.6/124.9 MB 3.2 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 72.6/124.9 MB 3.2 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 73.7/124.9 MB 3.2 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 74.7/124.9 MB 3.3 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 75.8/124.9 MB 3.3 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 76.5/124.9 MB 3.3 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 77.6/124.9 MB 3.3 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 78.9/124.9 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 80.0/124.9 MB 3.3 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 81.3/124.9 MB 3.4 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 82.6/124.9 MB 3.4 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 84.1/124.9 MB 3.4 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 85.5/124.9 MB 3.5 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 87.0/124.9 MB 3.5 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 88.3/124.9 MB 3.5 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 89.4/124.9 MB 3.5 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 90.7/124.9 MB 3.6 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 91.5/124.9 MB 3.6 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 92.3/124.9 MB 3.6 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 93.3/124.9 MB 3.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 94.4/124.9 MB 3.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 95.4/124.9 MB 3.6 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 96.5/124.9 MB 3.6 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 98.0/124.9 MB 3.6 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 99.1/124.9 MB 3.6 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 100.1/124.9 MB 3.6 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 101.2/124.9 MB 3.7 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 102.5/124.9 MB 3.7 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 104.1/124.9 MB 3.7 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 105.4/124.9 MB 3.7 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 106.7/124.9 MB 3.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 108.0/124.9 MB 3.8 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 109.1/124.9 MB 3.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 110.4/124.9 MB 3.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 112.5/124.9 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 113.2/124.9 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 114.3/124.9 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 115.3/124.9 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 116.4/124.9 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 117.4/124.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 118.5/124.9 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 119.3/124.9 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.1/124.9 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 121.1/124.9 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------------------  122.2/124.9 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.5/124.9 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.5/124.9 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.8/124.9 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 124.9/124.9 MB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install praw pandas numpy matplotlib seaborn nltk textblob spacy gensim scikit-learn xgboost tensorflow transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913135bd-2fa7-40df-81ba-71020ced5e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ca0114-a507-442a-aeb0-be723848cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "def setup_reddit_credentials():\n",
    "    \"\"\"Set up Reddit API credentials either from file or user input\"\"\"\n",
    "    credentials_path = './reddit_credentials.json'\n",
    "\n",
    "    try:\n",
    "        with open(credentials_path, 'r') as f:\n",
    "            credentials = json.load(f)\n",
    "            print(\"Loaded existing Reddit API credentials\")\n",
    "            return credentials\n",
    "    except FileNotFoundError:\n",
    "        print(\"Reddit API credentials not found. Please enter them:\")\n",
    "        credentials = {\n",
    "            'client_id': input(\"Enter your Reddit client ID: \"),\n",
    "            'client_secret': input(\"Enter your Reddit client secret: \"),\n",
    "            'user_agent': input(\"Enter your Reddit user agent (e.g., 'mental_health_research/0.1 by YOUR_USERNAME'): \")\n",
    "        }\n",
    "\n",
    "        with open(credentials_path, 'w') as f:\n",
    "            json.dump(credentials, f)\n",
    "\n",
    "        print(\"Credentials saved for future use\")\n",
    "        return credentials\n",
    "\n",
    "def initialize_reddit_api(credentials):\n",
    "    \"\"\"Initialize the Reddit API client using PRAW\"\"\"\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=credentials['client_id'],\n",
    "        client_secret=credentials['client_secret'],\n",
    "        user_agent=credentials['user_agent']\n",
    "    )\n",
    "    return reddit\n",
    "\n",
    "def collect_posts_from_subreddit(reddit, subreddit_name, target_count=30000):\n",
    "    \"\"\"Collect posts from a specific subreddit until reaching target count\"\"\"\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts = []\n",
    "\n",
    "    print(f\"Collecting data from r/{subreddit_name}...\")\n",
    "\n",
    "    sorting_methods = [\n",
    "        ('hot', 5000),\n",
    "        ('top', 'all', 5000),\n",
    "        ('new', 5000),\n",
    "        ('rising', 5000),\n",
    "        ('controversial', 'all', 5000)\n",
    "    ]\n",
    "\n",
    "    for method in sorting_methods:\n",
    "        if len(posts) >= target_count:\n",
    "            break\n",
    "\n",
    "        remaining = target_count - len(posts)\n",
    "        print(f\"Using {method[0]} sorting to collect {remaining} more posts...\")\n",
    "\n",
    "        try:\n",
    "            if len(method) == 2:\n",
    "                method_name, limit = method\n",
    "                submissions = getattr(subreddit, method_name)(limit=limit)\n",
    "            else:\n",
    "                method_name, time_filter, limit = method\n",
    "                submissions = getattr(subreddit, method_name)(time_filter=time_filter, limit=limit)\n",
    "\n",
    "            for submission in tqdm(submissions, total=limit, leave=False):\n",
    "                if not submission.stickied and submission.selftext and len(submission.selftext) > 50:\n",
    "                    posts.append({\n",
    "                        'id': submission.id,\n",
    "                        'title': submission.title,\n",
    "                        'text': submission.selftext,\n",
    "                        'created_utc': submission.created_utc,\n",
    "                        'score': submission.score,\n",
    "                        'num_comments': submission.num_comments,\n",
    "                        'subreddit': subreddit_name\n",
    "                    })\n",
    "\n",
    "                    if len(posts) >= target_count:\n",
    "                        break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting from {method[0]}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if len(posts) < target_count:\n",
    "        remaining = target_count - len(posts)\n",
    "        print(f\"Still need {remaining} posts. Using search to find more...\")\n",
    "\n",
    "        search_terms = [\"the\", \"I\", \"and\", \"to\", \"of\", \"a\", \"in\", \"is\", \"my\", \"that\", \"this\", \"for\", \"with\"]\n",
    "\n",
    "        for term in search_terms:\n",
    "            search_results = subreddit.search(term, sort=\"relevance\", limit=30000)\n",
    "            for submission in search_results:\n",
    "                if not submission.stickied and submission.selftext and len(submission.selftext) > 50:\n",
    "                    # Check if we already have this post (by ID)\n",
    "                    if not any(post['id'] == submission.id for post in posts):\n",
    "                        posts.append({\n",
    "                            'id': submission.id,\n",
    "                            'title': submission.title,\n",
    "                            'text': submission.selftext,\n",
    "                            'created_utc': submission.created_utc,\n",
    "                            'score': submission.score,\n",
    "                            'num_comments': submission.num_comments,\n",
    "                            'subreddit': subreddit_name\n",
    "                        })\n",
    "\n",
    "                        if len(posts) >= target_count:\n",
    "                            break\n",
    "\n",
    "            if len(posts) >= target_count:\n",
    "                break\n",
    "\n",
    "    print(f\"Collected {len(posts)} posts from r/{subreddit_name}\")\n",
    "    return posts\n",
    "\n",
    "def collect_clinical_and_non_clinical_data(reddit, posts_per_subreddit=30000):\n",
    "    \"\"\"Collect data from both clinical and non-clinical subreddits\"\"\"\n",
    "    base_path = './'\n",
    "\n",
    "    clinical_subreddits = {\n",
    "        'ADHD': 'ADHD',\n",
    "        'Anxiety': 'Anxiety',\n",
    "        'Bipolar': 'bipolar',\n",
    "        'Depression': 'depression',\n",
    "        'EatingDisorders': 'EatingDisorders',\n",
    "        'OCD': 'OCD',\n",
    "        'PTSD': 'ptsd',\n",
    "        'Schizophrenia': 'schizophrenia',\n",
    "        'SuicideWatch': 'SuicideWatch',\n",
    "        'BPD': 'BPD',  \n",
    "        'Stress': 'Stress'\n",
    "    }\n",
    "\n",
    "    non_clinical_subreddits = {\n",
    "        'AskReddit': 'AskReddit',\n",
    "        'CasualConversation': 'CasualConversation',\n",
    "        'Fitness': 'Fitness',\n",
    "        'Cooking': 'Cooking',\n",
    "        'Gaming': 'gaming',\n",
    "        'Movies': 'movies',\n",
    "        'Music': 'Music',\n",
    "        'Science': 'science',\n",
    "        'Technology': 'technology',\n",
    "        'Travel': 'travel'\n",
    "    }\n",
    "\n",
    "    clinical_posts = []\n",
    "    for disorder, subreddit in clinical_subreddits.items():\n",
    "        try:\n",
    "            file_path = f\"{base_path}data_raw_{subreddit}.csv\"\n",
    "            if os.path.exists(file_path):\n",
    "                print(f\"Found existing data for r/{subreddit}. Loading...\")\n",
    "                df_subreddit = pd.read_csv(file_path)\n",
    "                posts = df_subreddit.to_dict('records')\n",
    "                print(f\"Loaded {len(posts)} posts from r/{subreddit}\")\n",
    "            else:\n",
    "                posts = collect_posts_from_subreddit(reddit, subreddit, posts_per_subreddit)\n",
    "                for post in posts:\n",
    "                    post['category'] = 'clinical'\n",
    "                    post['disorder'] = disorder\n",
    "\n",
    "                df_subreddit = pd.DataFrame(posts)\n",
    "                df_subreddit.to_csv(file_path, index=False)\n",
    "                print(f\"Saved {len(posts)} posts from r/{subreddit}\")\n",
    "\n",
    "            clinical_posts.extend(posts)\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting from r/{subreddit}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    non_clinical_posts = []\n",
    "    for category, subreddit in non_clinical_subreddits.items():\n",
    "        try:\n",
    "            file_path = f\"{base_path}data_raw_{subreddit}.csv\"\n",
    "            if os.path.exists(file_path):\n",
    "                print(f\"Found existing data for r/{subreddit}. Loading...\")\n",
    "                df_subreddit = pd.read_csv(file_path)\n",
    "                posts = df_subreddit.to_dict('records')\n",
    "                print(f\"Loaded {len(posts)} posts from r/{subreddit}\")\n",
    "            else:\n",
    "                posts = collect_posts_from_subreddit(reddit, subreddit, posts_per_subreddit)\n",
    "                for post in posts:\n",
    "                    post['category'] = 'non-clinical'\n",
    "                    post['disorder'] = 'none'  # No disorder for non-clinical posts\n",
    "\n",
    "                df_subreddit = pd.DataFrame(posts)\n",
    "                df_subreddit.to_csv(file_path, index=False)\n",
    "                print(f\"Saved {len(posts)} posts from r/{subreddit}\")\n",
    "\n",
    "            non_clinical_posts.extend(posts)\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting from r/{subreddit}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    all_posts = clinical_posts + non_clinical_posts\n",
    "    df_all = pd.DataFrame(all_posts)\n",
    "\n",
    "    df_all.to_csv(f\"{base_path}reddit_mental_health_dataset_raw.csv\", index=False)\n",
    "\n",
    "    df_clinical = pd.DataFrame(clinical_posts)\n",
    "    df_clinical.to_csv(f\"{base_path}reddit_clinical_dataset_raw.csv\", index=False)\n",
    "\n",
    "    df_non_clinical = pd.DataFrame(non_clinical_posts)\n",
    "    df_non_clinical.to_csv(f\"{base_path}reddit_non_clinical_dataset_raw.csv\", index=False)\n",
    "\n",
    "    print(\"\\nData Collection Summary:\")\n",
    "    print(f\"Total posts collected: {len(all_posts)}\")\n",
    "    print(f\"Clinical posts: {len(clinical_posts)}\")\n",
    "    print(f\"Non-clinical posts: {len(non_clinical_posts)}\")\n",
    "\n",
    "    print(\"\\nPosts by subreddit:\")\n",
    "    subreddit_counts = df_all['subreddit'].value_counts()\n",
    "    for subreddit, count in subreddit_counts.items():\n",
    "        print(f\"  r/{subreddit}: {count} posts\")\n",
    "\n",
    "    return df_clinical, df_non_clinical, df_all\n",
    "\n",
    "def run_data_collection():\n",
    "    print(\"Starting Reddit data collection for mental health detection...\\n\")\n",
    "\n",
    "    try:\n",
    "        credentials = setup_reddit_credentials()\n",
    "        reddit = initialize_reddit_api(credentials)\n",
    "\n",
    "        print(f\"Connected to Reddit as: {reddit.user.me() or 'Read-only mode'}\")\n",
    "\n",
    "        posts_per_subreddit = 30000\n",
    "\n",
    "        df_clinical, df_non_clinical, df_all = collect_clinical_and_non_clinical_data(reddit, posts_per_subreddit)\n",
    "\n",
    "        print(\"\\nData collection completed successfully!\")\n",
    "        print(f\"Clinical dataset shape: {df_clinical.shape}\")\n",
    "        print(f\"Non-clinical dataset shape: {df_non_clinical.shape}\")\n",
    "        print(f\"Combined dataset shape: {df_all.shape}\")\n",
    "\n",
    "        return df_clinical, df_non_clinical, df_all\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data collection: {str(e)}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9293b41-98c0-4559-9ef9-2aa7c49ed190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Reddit data collection for mental health detection...\n",
      "\n",
      "Reddit API credentials not found. Please enter them:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Reddit client ID:  PU2yUedhMR9BEs170mGbhQ\n",
      "Enter your Reddit client secret:  wM4k9ThQV2gdjQjfz59bWLgGXFwEeQ\n",
      "Enter your Reddit user agent (e.g., 'mental_health_research/0.1 by YOUR_USERNAME'):  blackwarrant1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials saved for future use\n",
      "Connected to Reddit as: Read-only mode\n",
      "Collecting data from r/ADHD...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29465 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28505 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27525 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27500 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 26572 posts. Using search to find more...\n",
      "Collected 4341 posts from r/ADHD\n",
      "Saved 4341 posts from r/ADHD\n",
      "Collecting data from r/Anxiety...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29049 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28327 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27381 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27357 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 26492 posts. Using search to find more...\n",
      "Collected 4368 posts from r/Anxiety\n",
      "Saved 4368 posts from r/Anxiety\n",
      "Collecting data from r/bipolar...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29168 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 29106 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 28121 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 28096 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 27334 posts. Using search to find more...\n",
      "Collected 3774 posts from r/bipolar\n",
      "Saved 3774 posts from r/bipolar\n",
      "Collecting data from r/depression...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29208 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28316 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27348 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27323 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 26424 posts. Using search to find more...\n",
      "Collected 4429 posts from r/depression\n",
      "Saved 4429 posts from r/depression\n",
      "Collecting data from r/EatingDisorders...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29022 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28041 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27054 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27030 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 26061 posts. Using search to find more...\n",
      "Collected 5045 posts from r/EatingDisorders\n",
      "Saved 5045 posts from r/EatingDisorders\n",
      "Collecting data from r/OCD...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29041 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28862 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27892 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27868 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 27015 posts. Using search to find more...\n",
      "Collected 4135 posts from r/OCD\n",
      "Saved 4135 posts from r/OCD\n",
      "Collecting data from r/ptsd...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29024 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28080 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27102 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27077 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 26139 posts. Using search to find more...\n",
      "Collected 4735 posts from r/ptsd\n",
      "Saved 4735 posts from r/ptsd\n",
      "Collecting data from r/schizophrenia...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29152 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 29031 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 28176 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 28156 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 27362 posts. Using search to find more...\n",
      "Collected 3606 posts from r/schizophrenia\n",
      "Saved 3606 posts from r/schizophrenia\n",
      "Collecting data from r/SuicideWatch...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29203 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28381 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27454 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27429 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 26562 posts. Using search to find more...\n",
      "Collected 4444 posts from r/SuicideWatch\n",
      "Saved 4444 posts from r/SuicideWatch\n",
      "Collecting data from r/BPD...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29148 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28182 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27189 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27164 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 26197 posts. Using search to find more...\n",
      "Collected 5092 posts from r/BPD\n",
      "Saved 5092 posts from r/BPD\n",
      "Collecting data from r/Stress...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29061 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28153 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27248 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27224 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 26352 posts. Using search to find more...\n",
      "Collected 4270 posts from r/Stress\n",
      "Saved 4270 posts from r/Stress\n",
      "Collecting data from r/AskReddit...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 29987 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 29987 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 29987 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 29633 posts. Using search to find more...\n",
      "Collected 476 posts from r/AskReddit\n",
      "Saved 476 posts from r/AskReddit\n",
      "Collecting data from r/CasualConversation...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29257 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28289 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27413 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27388 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 26421 posts. Using search to find more...\n",
      "Collected 4298 posts from r/CasualConversation\n",
      "Saved 4298 posts from r/CasualConversation\n",
      "Collecting data from r/Fitness...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29965 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28981 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27990 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27967 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 27063 posts. Using search to find more...\n",
      "Collected 3673 posts from r/Fitness\n",
      "Saved 3673 posts from r/Fitness\n",
      "Collecting data from r/Cooking...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29087 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 28232 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 27343 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 27318 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 26475 posts. Using search to find more...\n",
      "Collected 4292 posts from r/Cooking\n",
      "Saved 4292 posts from r/Cooking\n",
      "Collecting data from r/gaming...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29641 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 29630 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 29088 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 29077 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 29019 posts. Using search to find more...\n",
      "Collected 1451 posts from r/gaming\n",
      "Saved 1451 posts from r/gaming\n",
      "Collecting data from r/movies...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29525 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 29469 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 28728 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 28727 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 28135 posts. Using search to find more...\n",
      "Collected 2602 posts from r/movies\n",
      "Saved 2602 posts from r/movies\n",
      "Collecting data from r/Music...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29842 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 29674 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 29413 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 29412 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 29040 posts. Using search to find more...\n",
      "Collected 1469 posts from r/Music\n",
      "Saved 1469 posts from r/Music\n",
      "Collecting data from r/science...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 29994 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 29994 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 29994 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 29973 posts. Using search to find more...\n",
      "Collected 325 posts from r/science\n",
      "Saved 325 posts from r/science\n",
      "Collecting data from r/technology...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 29982 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 29982 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 29982 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 29957 posts. Using search to find more...\n",
      "Collected 59 posts from r/technology\n",
      "Saved 59 posts from r/technology\n",
      "Collecting data from r/travel...\n",
      "Using hot sorting to collect 30000 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top sorting to collect 29353 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using new sorting to collect 29296 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rising sorting to collect 29117 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using controversial sorting to collect 29094 more posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still need 28201 posts. Using search to find more...\n",
      "Collected 2566 posts from r/travel\n",
      "Saved 2566 posts from r/travel\n",
      "\n",
      "Data Collection Summary:\n",
      "Total posts collected: 69450\n",
      "Clinical posts: 48239\n",
      "Non-clinical posts: 21211\n",
      "\n",
      "Posts by subreddit:\n",
      "  r/BPD: 5092 posts\n",
      "  r/EatingDisorders: 5045 posts\n",
      "  r/ptsd: 4735 posts\n",
      "  r/SuicideWatch: 4444 posts\n",
      "  r/depression: 4429 posts\n",
      "  r/Anxiety: 4368 posts\n",
      "  r/ADHD: 4341 posts\n",
      "  r/CasualConversation: 4298 posts\n",
      "  r/Cooking: 4292 posts\n",
      "  r/Stress: 4270 posts\n",
      "  r/OCD: 4135 posts\n",
      "  r/bipolar: 3774 posts\n",
      "  r/Fitness: 3673 posts\n",
      "  r/schizophrenia: 3606 posts\n",
      "  r/movies: 2602 posts\n",
      "  r/travel: 2566 posts\n",
      "  r/Music: 1469 posts\n",
      "  r/gaming: 1451 posts\n",
      "  r/AskReddit: 476 posts\n",
      "  r/science: 325 posts\n",
      "  r/technology: 59 posts\n",
      "\n",
      "Data collection completed successfully!\n",
      "Clinical dataset shape: (48239, 9)\n",
      "Non-clinical dataset shape: (21211, 9)\n",
      "Combined dataset shape: (69450, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>category</th>\n",
       "      <th>disorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1joyhmu</td>\n",
       "      <td>People who were diagnosed late in life, what's...</td>\n",
       "      <td>For me it was my exceptional ability to make i...</td>\n",
       "      <td>1.743521e+09</td>\n",
       "      <td>1472</td>\n",
       "      <td>793</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>clinical</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1jp2iex</td>\n",
       "      <td>Accidentally managed my ADHD at work</td>\n",
       "      <td>I (AuDHD) am at work, at a no-phone-calls offi...</td>\n",
       "      <td>1.743531e+09</td>\n",
       "      <td>477</td>\n",
       "      <td>82</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>clinical</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1jpf7td</td>\n",
       "      <td>Does your ADHD cause you to skip and stutter y...</td>\n",
       "      <td>Sometimes I just cannot get words out at all.....</td>\n",
       "      <td>1.743564e+09</td>\n",
       "      <td>67</td>\n",
       "      <td>34</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>clinical</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1jp5gle</td>\n",
       "      <td>What is a hobby that actually stuck for you?</td>\n",
       "      <td>A common experience for people with adhd is ho...</td>\n",
       "      <td>1.743538e+09</td>\n",
       "      <td>144</td>\n",
       "      <td>411</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>clinical</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1jpc5di</td>\n",
       "      <td>I think I figured out why I/we eat faster than...</td>\n",
       "      <td>So I noticed while I was eating dinner just no...</td>\n",
       "      <td>1.743556e+09</td>\n",
       "      <td>39</td>\n",
       "      <td>153</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>clinical</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  1joyhmu  People who were diagnosed late in life, what's...   \n",
       "1  1jp2iex               Accidentally managed my ADHD at work   \n",
       "2  1jpf7td  Does your ADHD cause you to skip and stutter y...   \n",
       "3  1jp5gle       What is a hobby that actually stuck for you?   \n",
       "4  1jpc5di  I think I figured out why I/we eat faster than...   \n",
       "\n",
       "                                                text   created_utc  score  \\\n",
       "0  For me it was my exceptional ability to make i...  1.743521e+09   1472   \n",
       "1  I (AuDHD) am at work, at a no-phone-calls offi...  1.743531e+09    477   \n",
       "2  Sometimes I just cannot get words out at all.....  1.743564e+09     67   \n",
       "3  A common experience for people with adhd is ho...  1.743538e+09    144   \n",
       "4  So I noticed while I was eating dinner just no...  1.743556e+09     39   \n",
       "\n",
       "   num_comments subreddit  category disorder  \n",
       "0           793      ADHD  clinical     ADHD  \n",
       "1            82      ADHD  clinical     ADHD  \n",
       "2            34      ADHD  clinical     ADHD  \n",
       "3           411      ADHD  clinical     ADHD  \n",
       "4           153      ADHD  clinical     ADHD  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69450 entries, 0 to 69449\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            69450 non-null  object \n",
      " 1   title         69450 non-null  object \n",
      " 2   text          69450 non-null  object \n",
      " 3   created_utc   69450 non-null  float64\n",
      " 4   score         69450 non-null  int64  \n",
      " 5   num_comments  69450 non-null  int64  \n",
      " 6   subreddit     69450 non-null  object \n",
      " 7   category      69450 non-null  object \n",
      " 8   disorder      69450 non-null  object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Execute data collection\n",
    "clinical_df, non_clinical_df, all_df = run_data_collection()\n",
    "\n",
    "# Optionally display some collected data\n",
    "if all_df is not None:\n",
    "    display(all_df.head())\n",
    "    print(\"\\nDataset info:\")\n",
    "    all_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d0ed61-0a92-49ae-91c9-4638b319fea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unwanted subreddits removed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File path\n",
    "file_path = r'C:\\Users\\User\\Downloads\\SMA2\\reddit_mental_health_dataset_raw.csv'\n",
    "\n",
    "# Subreddits to remove\n",
    "unwanted_subreddits = [\n",
    "    'Cooking', 'Fitness', 'movies', 'travel',\n",
    "    'Music', 'gaming', 'AskReddit', 'science', 'technology'\n",
    "]\n",
    "\n",
    "# Read dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove unwanted subreddits\n",
    "filtered_df = df[~df['subreddit'].isin(unwanted_subreddits)]\n",
    "\n",
    "# Save the cleaned dataset\n",
    "filtered_df.to_csv('reddit_mental_health_dataset_cleaned1.csv', index=False)\n",
    "\n",
    "print(\"Unwanted subreddits removed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fe2f260-becb-4c9b-a2da-8b9f13089acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>category</th>\n",
       "      <th>disorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1joyhmu</td>\n",
       "      <td>People who were diagnosed late in life, what's...</td>\n",
       "      <td>For me it was my exceptional ability to make i...</td>\n",
       "      <td>1.743521e+09</td>\n",
       "      <td>1472</td>\n",
       "      <td>793</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>clinical</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1jp2iex</td>\n",
       "      <td>Accidentally managed my ADHD at work</td>\n",
       "      <td>I (AuDHD) am at work, at a no-phone-calls offi...</td>\n",
       "      <td>1.743531e+09</td>\n",
       "      <td>477</td>\n",
       "      <td>82</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>clinical</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1jpf7td</td>\n",
       "      <td>Does your ADHD cause you to skip and stutter y...</td>\n",
       "      <td>Sometimes I just cannot get words out at all.....</td>\n",
       "      <td>1.743564e+09</td>\n",
       "      <td>67</td>\n",
       "      <td>34</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>clinical</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1jp5gle</td>\n",
       "      <td>What is a hobby that actually stuck for you?</td>\n",
       "      <td>A common experience for people with adhd is ho...</td>\n",
       "      <td>1.743538e+09</td>\n",
       "      <td>144</td>\n",
       "      <td>411</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>clinical</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1jpc5di</td>\n",
       "      <td>I think I figured out why I/we eat faster than...</td>\n",
       "      <td>So I noticed while I was eating dinner just no...</td>\n",
       "      <td>1.743556e+09</td>\n",
       "      <td>39</td>\n",
       "      <td>153</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>clinical</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  1joyhmu  People who were diagnosed late in life, what's...   \n",
       "1  1jp2iex               Accidentally managed my ADHD at work   \n",
       "2  1jpf7td  Does your ADHD cause you to skip and stutter y...   \n",
       "3  1jp5gle       What is a hobby that actually stuck for you?   \n",
       "4  1jpc5di  I think I figured out why I/we eat faster than...   \n",
       "\n",
       "                                                text   created_utc  score  \\\n",
       "0  For me it was my exceptional ability to make i...  1.743521e+09   1472   \n",
       "1  I (AuDHD) am at work, at a no-phone-calls offi...  1.743531e+09    477   \n",
       "2  Sometimes I just cannot get words out at all.....  1.743564e+09     67   \n",
       "3  A common experience for people with adhd is ho...  1.743538e+09    144   \n",
       "4  So I noticed while I was eating dinner just no...  1.743556e+09     39   \n",
       "\n",
       "   num_comments subreddit  category disorder  \n",
       "0           793      ADHD  clinical     ADHD  \n",
       "1            82      ADHD  clinical     ADHD  \n",
       "2            34      ADHD  clinical     ADHD  \n",
       "3           411      ADHD  clinical     ADHD  \n",
       "4           153      ADHD  clinical     ADHD  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52537 entries, 0 to 53012\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            52537 non-null  object \n",
      " 1   title         52537 non-null  object \n",
      " 2   text          52537 non-null  object \n",
      " 3   created_utc   52537 non-null  float64\n",
      " 4   score         52537 non-null  int64  \n",
      " 5   num_comments  52537 non-null  int64  \n",
      " 6   subreddit     52537 non-null  object \n",
      " 7   category      52537 non-null  object \n",
      " 8   disorder      52537 non-null  object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "if filtered_df is not None:\n",
    "    display(filtered_df.head())\n",
    "    print(\"\\nDataset info:\")\n",
    "    filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a780561-77f7-4f7c-8205-7615fdbe9b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (52537, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Combined dataset shape: {filtered_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daee2bed-bbfd-4ea5-a0c0-63e7e05eb8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unwanted subreddits removed and 'None' replaced with 'Normal' in disorder column.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace 'None' in the 'disorder' column with 'Normal'\n",
    "filtered_df.loc[filtered_df['disorder'] == 'none', 'disorder'] = 'Normal'\n",
    "\n",
    "# Save the cleaned dataset\n",
    "filtered_df.to_csv('reddit_mental_health_dataset_cleaned_normal.csv', index=False)\n",
    "\n",
    "print(\"Unwanted subreddits removed and 'None' replaced with 'Normal' in disorder column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d03880-17d7-46fb-912d-b7743648fa8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
